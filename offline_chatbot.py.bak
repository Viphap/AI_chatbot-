# -*- coding: utf-8 -*-
"""Offline_Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17BVpZTqy-ypti-9A4Fcnexu6brAlFvVD
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')
import os
import re
import json
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
from dotenv import load_dotenv
import difflib

# ================================================================
# âš™ï¸ CONFIG / AUTH
# ================================================================
load_dotenv()

TB_USER = os.getenv("TB_USER") or input("Nháº­p username Newsense: ").strip()
TB_PASS = os.getenv("TB_PASS") or input("Nháº­p password Newsense: ").strip()
BASE_URL = os.getenv("BASE_URL") or "https://newsense.viphap.com/api"

# ================================================================
# ğŸ§  LOAD KNOWLEDGE GRAPH
# ================================================================
kg_path = "/content/drive/MyDrive/Knowledge graph.xlsx"
try:
    kg_df = pd.read_excel(kg_path)
    print(f"âœ… Loaded Knowledge Graph vá»›i {len(kg_df)} rows.")
except Exception as e:
    print(f"âŒ KHÃ”NG THá»‚ Táº¢I KNOWLEDGE GRAPH: {e}")
    kg_df = pd.DataFrame()

# ================================================================
# ğŸ—ºï¸ BUILD LOOKUP TABLES Tá»ª KNOWLEDGE GRAPH (thay tháº¿ Gemini)
# ================================================================
# Tá»± Ä‘á»™ng Ä‘á»c táº¥t cáº£ vá»‹ trÃ­ & loáº¡i dá»¯ liá»‡u tá»« KG â€” khÃ´ng hardcode

def build_lookup_tables(kg_df: pd.DataFrame):
    if kg_df.empty:
        return {}, {}, {}, [], []

    kg_records = kg_df.to_dict(orient="records")

    # --- 1. Location map (giá»¯ nguyÃªn cá»§a báº¡n) ---
    location_col = next((c for c in kg_df.columns if "vá»‹ trÃ­" in c.lower() or "location" in c.lower()), None)
    location_map = {}
    if location_col:
        for val in kg_df[location_col].dropna().unique():
            key = val.lower().strip()
            location_map[key] = val
            words = key.split()
            if len(words) >= 2:
                location_map[words[-1]] = val
                location_map["".join(w[0] for w in words)] = val
            if "Ä‘á»‘t há»£p long" in key:
                location_map["há»£p long"] = val

    # --- 2. Semantic Type Map ---
    SEMANTIC_TYPE_MAP = {
        "nhiá»‡t Ä‘á»™": ["nhiá»‡t Ä‘á»™", "nhiá»‡t", "temperature"],
        "Ä‘á»™ áº©m": ["humidity", "áº©m", "Ä‘á»™ áº©m"],
        "mÆ°a": ["rainfall", "rain", "mÆ°a"],
        "giÃ³": ["wind", "wind_speed", "giÃ³"],
        "mÃ´i trÆ°á»ng": ["nhiá»‡t Ä‘á»™", "Ä‘á»™ áº©m", "mÆ°a", "giÃ³"],
        "á»©ng suáº¥t": ["strain", "sg", "stress", "á»©ng suáº¥t"],
        "biáº¿n dáº¡ng": ["strain", "deformation"],
        "dao Ä‘á»™ng": ["acc", "vibration", "acceleration", "dao Ä‘á»™ng"],
        "rung": ["acc", "vibration"],
        "gia tá»‘c": ["acc", "acceleration"],
        "chuyá»ƒn vá»‹": ["displacement", "chuyá»ƒn vá»‹", "gnss"],
        "lÃºn": ["settlement", "lÃºn"],
        "lá»±c cÄƒng": ["loadcell", "force", "lá»±c cÄƒng"],
        "gnss": ["gnss", "gps"],          # Bá»• sung explicit keyword
        "loadcell": ["loadcell", "cÃ¡p"],  # Bá»• sung explicit keyword
    }

    # --- 3. Exact Var Map ---
    var_col = next((c for c in kg_df.columns if "tÃªn biáº¿n" in c.lower() or "key" in c.lower()), None)
    type_map = {}
    if var_col:
        for var_val in kg_df[var_col].dropna().unique():
            key = var_val.lower().strip()
            type_map[key] = var_val

    # --- 4. Tá»° Äá»˜NG Láº¤Y LOáº I THIáº¾T Bá»Š Tá»ª KG (Má»šI) ---
    type_col = next((c for c in kg_df.columns if "loáº¡i" in c.lower()), None)
    dynamic_device_types = []
    if type_col:
        dynamic_device_types = [str(x).lower().strip() for x in kg_df[type_col].dropna().unique()]

    return location_map, SEMANTIC_TYPE_MAP, type_map, dynamic_device_types, kg_records

# Cáº­p nháº­t lá»i gá»i hÃ m
location_map, semantic_type_map, exact_var_map, dynamic_device_types, kg_records = build_lookup_tables(kg_df)
print(f"âœ… ÄÃ£ build lookup: {len(location_map)} vá»‹ trÃ­, {len(dynamic_device_types)} loáº¡i thiáº¿t bá»‹ Ä‘á»™ng.")
# ================================================================
# ğŸ•“ INTERPRET RELATIVE TIME (giá»¯ nguyÃªn tá»« báº£n gá»‘c, Ä‘Ã£ tá»‘t)
# ================================================================
def interpret_relative_time(query: str):
    now = datetime.now()
    text = query.lower()

    if "hÃ´m nay" in text:
        start = now.replace(hour=0, minute=0, second=0)
        return start.strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")

    if "hÃ´m qua" in text:
        yesterday = now - timedelta(days=1)
        return yesterday.strftime("%Y-%m-%d"), yesterday.strftime("%Y-%m-%d")

    m = re.search(r"(\d+)\s*(ngÃ y|tuáº§n|thÃ¡ng|nÄƒm)", text)
    if m:
        n, unit = int(m.group(1)), m.group(2)
        if unit == "ngÃ y":   start = now - timedelta(days=n)
        elif unit == "tuáº§n": start = now - timedelta(weeks=n)
        elif unit == "thÃ¡ng":start = now - timedelta(days=n * 30)
        elif unit == "nÄƒm":  start = datetime(now.year - n + 1, 1, 1)
        return start.strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")

    if "tuáº§n nÃ y" in text:
        start = (now - timedelta(days=now.weekday())).replace(hour=0, minute=0, second=0)
        return start.strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")

    if "thÃ¡ng nÃ y" in text:
        return now.replace(day=1).strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")

    if "tá»« Ä‘áº§u nÄƒm" in text:
        return now.replace(month=1, day=1).strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")

    if "nÄƒm ngoÃ¡i" in text:
        y = now.year - 1
        return f"{y}-01-01", f"{y}-12-31"

    # NgÃ y tuyá»‡t Ä‘á»‘i dáº¡ng YYYY-MM-DD
    dates = re.findall(r"\d{4}-\d{2}-\d{2}", text)
    if len(dates) >= 2:
        return dates[0], dates[1]
    if len(dates) == 1:
        return dates[0], now.strftime("%Y-%m-%d")

    # NgÃ y dáº¡ng DD/MM/YYYY
    dates2 = re.findall(r"\d{1,2}/\d{1,2}/\d{4}", text)
    if dates2:
        parsed = [datetime.strptime(d, "%d/%m/%Y").strftime("%Y-%m-%d") for d in dates2]
        return (parsed[0], parsed[1]) if len(parsed) >= 2 else (parsed[0], now.strftime("%Y-%m-%d"))

    # Máº·c Ä‘á»‹nh: 30 ngÃ y gáº§n nháº¥t
    return (now - timedelta(days=30)).strftime("%Y-%m-%d"), now.strftime("%Y-%m-%d")

# ================================================================
# ğŸ” OFFLINE NLU ENGINE â€” thay tháº¿ hoÃ n toÃ n Gemini cho extraction
# ================================================================
def extract_location(text: str) -> str | None:
    """TÃ¬m vá»‹ trÃ­ trong cÃ¢u há»i báº±ng fuzzy match vá»›i location_map."""
    text_lower = text.lower()

    # 1. Khá»›p chÃ­nh xÃ¡c trÆ°á»›c
    for keyword, location in location_map.items():
        if keyword in text_lower:
            return location

    # 2. Fuzzy match náº¿u khÃ´ng khá»›p chÃ­nh xÃ¡c
    all_keys = list(location_map.keys())
    words = re.findall(r'\w+', text_lower)
    for word in words:
        matches = difflib.get_close_matches(word, all_keys, n=1, cutoff=0.82)
        if matches:
            return location_map[matches[0]]

    return None

def extract_data_types(text: str) -> list[str]:
    """TÃ¬m loáº¡i dá»¯ liá»‡u/thiáº¿t bá»‹ tá»« cÃ¢u há»i báº±ng Regex & Fuzzy Match."""
    text_lower = text.lower()
    found_patterns = set()

    # 1. Khá»›p báº±ng Word Boundary cho SEMANTIC_MAP (TrÃ¡nh lá»—i dÃ­nh chá»¯)
    for keyword, patterns in semantic_type_map.items():
        # DÃ¹ng regex \b Ä‘á»ƒ báº¯t chÃ­nh xÃ¡c tá»« khÃ³a Ä‘á»©ng Ä‘á»™c láº­p
        if re.search(r'\b' + re.escape(keyword) + r'\b', text_lower):
            found_patterns.update(patterns)

    # 2. QuÃ©t thÃ´ng minh (Fuzzy match) trá»±c tiáº¿p cÃ¡c "Loáº¡i thiáº¿t bá»‹" cÃ³ trong KG
    words = text_lower.split()
    for dt in dynamic_device_types:
        # Náº¿u cá»¥m tá»« thiáº¿t bá»‹ náº±m trá»n trong cÃ¢u (vd: "loadcell")
        if dt in text_lower:
            found_patterns.add(dt)
        else:
            # Náº¿u gÃµ sai chÃ­nh táº£ má»™t chÃºt (vd: "loadcel" -> "loadcell", tá»· lá»‡ giá»‘ng > 85%)
            for word in words:
                if difflib.SequenceMatcher(None, word, dt).ratio() > 0.85:
                    found_patterns.add(dt)

    # 3. Khá»›p chÃ­nh xÃ¡c tÃªn biáº¿n (náº¿u ngÆ°á»i dÃ¹ng gÃµ tháº³ng tÃªn biáº¿n)
    for keyword, var_name in exact_var_map.items():
        if keyword in text_lower:
            found_patterns.add(var_name)

    print(f"DEBUG: Keyword nháº­n diá»‡n Ä‘Æ°á»£c -> {list(found_patterns)}")
    return list(found_patterns)

def filter_devices_from_kg(location: str | None, data_type_patterns: list[str]) -> list[dict]:
    """
    Filter Knowledge Graph Ä‘á»ƒ láº¥y devices phÃ¹ há»£p.
    ÄÃ¢y lÃ  bÆ°á»›c thay tháº¿ chÃ­nh xÃ¡c pháº§n Gemini gá»­i toÃ n bá»™ KG.
    """
    if not kg_records:
        return []

    # TÃ¬m cÃ¡c cá»™t liÃªn quan
    location_col = next((c for c in kg_df.columns if "vá»‹ trÃ­" in c.lower() or "location" in c.lower()), None)
    var_col = next((c for c in kg_df.columns if "tÃªn biáº¿n" in c.lower() or "key" in c.lower()), None)
    device_col = next((c for c in kg_df.columns if c.lower() == "device"), None)
    name_col = next((c for c in kg_df.columns if "tÃªn thiáº¿t bá»‹" in c.lower()), None)
    type_col = next((c for c in kg_df.columns if "loáº¡i" in c.lower()), None)

    filtered = []
    for row in kg_records:
        row_name = row.get(name_col or "TÃªn thiáº¿t bá»‹", "")
        row_device_id_name = row.get(device_col or "Device", "")
        row_var = str(row.get(var_col or "TÃªn biáº¿n", "")).lower()
        row_type = str(row.get(type_col or "Loáº¡i thiáº¿t bá»‹", "")).lower()

        # FIX Lá»–I á» ÄÃ‚Y: Láº¥y giÃ¡ trá»‹ row_loc ngay tá»« Ä‘áº§u Ä‘á»ƒ trÃ¡nh UnboundLocalError
        row_loc = str(row.get(location_col, "")).lower() if location_col else ""

        # Filter theo vá»‹ trÃ­ (Náº¿u ngÆ°á»i dÃ¹ng nháº­p vá»‹ trÃ­)
        loc_match = True
        if location:
            if location.lower() not in row_loc:
                loc_match = False

        if not loc_match:
            continue

        # Filter theo loáº¡i dá»¯ liá»‡u/keyword
        type_pattern_match = False
        if data_type_patterns:
            var_match = False
            if var_col:
                var_match = any(p.lower() in row_var for p in data_type_patterns)

            type_match = False
            if type_col:
                type_match = any(p.lower() in row_type for p in data_type_patterns)

            type_pattern_match = var_match or type_match
        else:
            type_pattern_match = True

        if loc_match and type_pattern_match:
            filtered.append({
                "TÃªn thiáº¿t bá»‹": row_name,
                "Device": row_device_id_name,
                "TÃªn biáº¿n": row.get(var_col or "TÃªn biáº¿n", ""),
                "Loáº¡i thiáº¿t bá»‹": row_type,
            })

    return filtered

def parse_query_offline(query: str) -> dict:
    """
    ğŸ”‘ HÃ€M CHÃNH â€” thay tháº¿ hoÃ n toÃ n chatbot() + Gemini.
    PhÃ¢n tÃ­ch cÃ¢u há»i 100% offline, khÃ´ng gá»i API.
    """
    text = query.strip()

    # 1. Thá»i gian
    start_date, end_date = interpret_relative_time(text)

    # 2. Vá»‹ trÃ­
    location = extract_location(text)

    # 3. Loáº¡i dá»¯ liá»‡u / Thiáº¿t bá»‹
    data_type_patterns = extract_data_types(text)
    print(f"DEBUG: parse_query_offline - data_type_patterns from extract_data_types: {data_type_patterns}")

    # 4. Lá»c devices tá»« KG
    devices = filter_devices_from_kg(location, data_type_patterns)
    print(f"DEBUG: parse_query_offline - devices after first filter (with patterns): {devices}")

    # 5. Fallback: Náº¿u khÃ´ng tÃ¬m tháº¥y loáº¡i dá»¯ liá»‡u nhÆ°ng cÃ³ vá»‹ trÃ­ â†’ láº¥y táº¥t cáº£
    if not devices and location:
        print(f"   â„¹ï¸  KhÃ´ng rÃµ loáº¡i thiáº¿t bá»‹ â€” láº¥y táº¥t cáº£ biáº¿n táº¡i '{location}'")
        devices = filter_devices_from_kg(location, [])
        print(f"DEBUG: parse_query_offline - devices after fallback filter (no patterns): {devices}")

    # ÄÃ³ng ngoáº·c result (Ä‘oáº¡n code cá»§a báº¡n bá»‹ thiáº¿u pháº§n nÃ y)
    result = {
        "start_date": start_date,
        "end_date": end_date,
        "location": location,
        "data_type_patterns": data_type_patterns,
        "devices_found": len(devices),
        "devices": devices
    }

    return result

# ================================================================
# ğŸ“Š OFFLINE ANALYSIS ENGINE â€” thay tháº¿ Gemini analyze_data()
# ================================================================

# NgÆ°á»¡ng cáº£nh bÃ¡o theo loáº¡i biáº¿n (tÃ¹y chá»‰nh theo dá»± Ã¡n cá»§a báº¡n)
THRESHOLDS = {
    "temperature": {"warn_high": 45, "warn_low": -5,  "unit": "Â°C"},
    "temp":        {"warn_high": 45, "warn_low": -5,  "unit": "Â°C"},
    "humidity":    {"warn_high": 95, "warn_low": 20,  "unit": "%"},
    "strain":      {"warn_high": 500, "warn_low": -500,"unit": "Î¼Îµ"},
    "sg":          {"warn_high": 500, "warn_low": -500,"unit": "Î¼Îµ"},
    "acc":         {"warn_high": 0.5, "warn_low": -0.5,"unit": "g"},
    "vibration":   {"warn_high": 0.5, "warn_low": -0.5,"unit": "g"},
    "rainfall":    {"warn_high": 100, "warn_low": 0,  "unit": "mm"},
    "wind":        {"warn_high": 30,  "warn_low": 0,  "unit": "m/s"},
    "water_level": {"warn_high": 10,  "warn_low": -10, "unit": "m"},
}

def detect_anomalies(df: pd.DataFrame, key_lower: str) -> list[str]:
    """PhÃ¡t hiá»‡n báº¥t thÆ°á»ng dá»±a trÃªn IQR + threshold."""
    alerts = []
    if df.empty or "value" not in df.columns:
        return alerts

    # IQR method
    Q1, Q3 = df["value"].quantile(0.25), df["value"].quantile(0.75)
    IQR = Q3 - Q1
    outliers = df[(df["value"] < Q1 - 2.5 * IQR) | (df["value"] > Q3 + 2.5 * IQR)]
    if len(outliers) > 0:
        alerts.append(f"âš ï¸  PhÃ¡t hiá»‡n {len(outliers)} Ä‘iá»ƒm báº¥t thÆ°á»ng (ngoÃ i IQRÃ—2.5)")

    # Threshold check
    for key_pattern, limits in THRESHOLDS.items():
        if key_pattern in key_lower:
            hi, lo = limits["warn_high"], limits["warn_low"]
            over_high = (df["value"] > hi).sum()
            over_low  = (df["value"] < lo).sum()
            if over_high > 0:
                alerts.append(f"ğŸ”´ {over_high} Ä‘iá»ƒm vÆ°á»£t ngÆ°á»¡ng cao ({hi} {limits['unit']})")
            if over_low > 0:
                alerts.append(f"ğŸ”µ {over_low} Ä‘iá»ƒm dÆ°á»›i ngÆ°á»¡ng tháº¥p ({lo} {limits['unit']})")
            break

    return alerts

def trend_description(df: pd.DataFrame) -> str:
    """MÃ´ táº£ xu hÆ°á»›ng tÄƒng/giáº£m/á»•n Ä‘á»‹nh báº±ng linear regression Ä‘Æ¡n giáº£n."""
    if len(df) < 3:
        return "khÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch xu hÆ°á»›ng"

    x = np.arange(len(df))
    y = df["value"].values
    slope = np.polyfit(x, y, 1)[0]

    std = df["value"].std()
    mean = df["value"].mean()
    cv = (std / mean * 100) if mean != 0 else 0  # Coefficient of variation

    if abs(slope) < 0.001 * abs(mean):
        trend = "á»•n Ä‘á»‹nh"
    elif slope > 0:
        trend = f"cÃ³ xu hÆ°á»›ng TÄ‚NG nháº¹ (+{slope:.4f}/Ä‘iá»ƒm)"
    else:
        trend = f"cÃ³ xu hÆ°á»›ng GIáº¢M nháº¹ ({slope:.4f}/Ä‘iá»ƒm)"

    stability = "biáº¿n Ä‘á»™ng cao" if cv > 30 else ("biáº¿n Ä‘á»™ng vá»«a" if cv > 10 else "á»•n Ä‘á»‹nh")
    return f"{trend}, {stability} (CV={cv:.1f}%)"

def analyze_data_offline(fetched_data_list: list, original_query: str):
    """
    ğŸ”‘ PhÃ¢n tÃ­ch thá»‘ng kÃª + phÃ¡t hiá»‡n báº¥t thÆ°á»ng + mÃ´ táº£ xu hÆ°á»›ng + Láº¥y giÃ¡ trá»‹ má»›i nháº¥t.
    """
    print("\n" + "=" * 50)
    print("ğŸ” PHÃ‚N TÃCH Dá»® LIá»†U (Offline Engine)")
    print("=" * 50)

    if not fetched_data_list:
        print("   - KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ phÃ¢n tÃ­ch.")
        return

    for item in fetched_data_list:
        df   = item["data"]
        label = item["label"]
        key_lower = label.lower()

        print(f"\nğŸ“Œ {label}")
        print("   " + "-" * 46)

        if df.empty or "value" not in df.columns:
            print("   â„¹ï¸  KhÃ´ng cÃ³ dá»¯ liá»‡u.")
            continue

        mean_val = df["value"].mean()
        min_val  = df["value"].min()
        max_val  = df["value"].max()
        std_val  = df["value"].std()
        n        = len(df)

        # --- Láº¤Y GIÃ TRá»Š Má»šI NHáº¤T á» ÄÃ‚Y ---
        latest_row = df.iloc[-1]
        latest_val = latest_row["value"]
        latest_ts = latest_row["ts"].strftime('%Y-%m-%d %H:%M:%S')

        # TÃ¬m unit tá»« THRESHOLDS
        unit = ""
        for k, v in THRESHOLDS.items():
            if k in key_lower:
                unit = v["unit"]
                break

        # Thá»‘ng kÃª cÆ¡ báº£n
        print(f"   ğŸŸ¢ Má»šI NHáº¤T       : {latest_val:.3f} {unit} (Cáº­p nháº­t lÃºc {latest_ts})")
        print(f"   ğŸ“Š Sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u: {n}")
        print(f"   ğŸ“ˆ Cao nháº¥t       : {max_val:.3f} {unit}")
        print(f"   ğŸ“‰ Tháº¥p nháº¥t      : {min_val:.3f} {unit}")
        print(f"   ã€°ï¸  Trung bÃ¬nh     : {mean_val:.3f} {unit}")

        # Thá»i gian Ä‘á»‰nh
        idx_max = df["value"].idxmax()
        idx_min = df["value"].idxmin()
        print(f"   ğŸ• Äá»‰nh cao nháº¥t lÃºc: {df.loc[idx_max, 'ts'].strftime('%Y-%m-%d %H:%M')}")
        print(f"   ğŸ• Äá»‰nh tháº¥p nháº¥t lÃºc: {df.loc[idx_min, 'ts'].strftime('%Y-%m-%d %H:%M')}")

        # Xu hÆ°á»›ng
        trend = trend_description(df)
        print(f"   ğŸ“¡ Xu hÆ°á»›ng       : {trend}")

        # Cáº£nh bÃ¡o báº¥t thÆ°á»ng
        alerts = detect_anomalies(df, key_lower)
        if alerts:
            print("   ğŸš¨ Cáº£nh bÃ¡o:")
            for a in alerts:
                print(f"      {a}")
        else:
            print("   âœ… KhÃ´ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng")

    print("\n" + "=" * 50)

# ================================================================
# ğŸ›‘ NEWSENSE CLIENT (giá»¯ nguyÃªn tá»« báº£n gá»‘c)
# ================================================================
class NewsenseClient:
    def __init__(self, base_url, username, password):
        self.base_url = base_url.rstrip('/')
        self.username = username
        self.password = password
        self.token = self.login()

    def login(self):
        resp = requests.post(f"{self.base_url}/auth/login",
                             json={"username": self.username, "password": self.password})
        if resp.status_code == 401:
            raise Exception("âŒ Sai username hoáº·c máº­t kháº©u.")
        resp.raise_for_status()
        print("âœ… ÄÄƒng nháº­p Newsense thÃ nh cÃ´ng.")
        return resp.json().get("token")

    def get_devices(self):
        headers = {"X-Authorization": f"Bearer {self.token}"}
        page, devices = 0, []
        while True:
            resp = requests.get(f"{self.base_url}/tenant/devices", headers=headers,
                                params={"pageSize": 100, "page": page})
            resp.raise_for_status()
            data = resp.json()
            for d in data.get("data", []):
                devices.append({"id": d["id"]["id"], "name": d["name"]})
            if not data.get("hasNextPage"):
                break
            page += 1
        return devices

    def get_timeseries(self, device_id, key, start_date_str, end_date_str):
        headers = {"X-Authorization": f"Bearer {self.token}"}
        url = f"{self.base_url}/plugins/telemetry/DEVICE/{device_id}/values/timeseries"

        try:
            start_dt = datetime.strptime(start_date_str, "%Y-%m-%d").replace(hour=0, minute=0, second=0)
            end_dt   = datetime.strptime(end_date_str,   "%Y-%m-%d").replace(hour=23, minute=59, second=59)
            start_ts = int(start_dt.timestamp() * 1000)
            end_ts   = int(end_dt.timestamp()   * 1000)
        except ValueError:
            print("âŒ Äá»‹nh dáº¡ng ngÃ y khÃ´ng há»£p lá»‡.")
            return pd.DataFrame()

        duration_days = (end_dt - start_dt).days
        params = {"startTs": start_ts, "endTs": end_ts, "keys": key}

        if duration_days > 90:
            params.update({"interval": 86400000 * 7, "agg": "AVG"})
            print(f"   - Tá»•ng há»£p theo TUáº¦N cho {key}")
        elif duration_days > 7:
            params.update({"interval": 86400000, "agg": "AVG"})
            print(f"   - Tá»•ng há»£p theo NGÃ€Y cho {key}")
        else:
            params["limit"] = 10000
            print(f"   - Dá»¯ liá»‡u thÃ´ cho {key}")

        resp = requests.get(url, headers=headers, params=params)
        if resp.status_code != 200:
            print(f"âš ï¸ HTTP {resp.status_code}: {resp.text[:200]}")
            return pd.DataFrame()

        data = resp.json().get(key, [])
        if not data:
            return pd.DataFrame()

        df = pd.DataFrame(data)
        df["ts"]    = pd.to_datetime(df["ts"], unit="ms")
        df["value"] = pd.to_numeric(df["value"], errors="coerce")
        return df[["ts", "value"]].dropna(subset=["value"])

# ================================================================
# ğŸš€ MAIN LOOP
# ================================================================
try:
    client = NewsenseClient(BASE_URL, TB_USER, TB_PASS)
    all_devices = client.get_devices()
    device_name_to_id_map = {d["name"]: d["id"] for d in all_devices}
    print(f"âœ… ÄÃ£ táº£i {len(device_name_to_id_map)} thiáº¿t bá»‹ tá»« Newsense.")
except Exception as e:
    print(f"âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o Newsense Client: {e}")
    client = None
    device_name_to_id_map = {}

print("\nğŸ¤– Chatbot Offline sáºµn sÃ ng. GÃµ 'exit' Ä‘á»ƒ thoÃ¡t.")
print("ğŸ’¡ VÃ­ dá»¥: 'GNSS 3 ngÃ y gáº§n Ä‘Ã¢y'\n")

while True:
    # 1. Báº£o vá»‡ toÃ n bá»™ quÃ¡ trÃ¬nh báº±ng try...except Ä‘á»ƒ khÃ´ng bá»‹ sáº­p vÃ²ng láº·p
    try:
        query = input("\nBáº¡n: ").strip()
        if not query:
            continue

        if query.lower() in ["exit", "quit", "q", "thoÃ¡t"]:
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break

        if not client:
            print("âŒ Client Newsense chÆ°a khá»Ÿi táº¡o.")
            continue

        # â”€â”€ BÆ¯á»šC 1: PhÃ¢n tÃ­ch offline (khÃ´ng cáº§n Gemini) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        result = parse_query_offline(query)

        print("\nğŸ§  Káº¿t quáº£ phÃ¢n tÃ­ch (Offline):")
        print(json.dumps(result, ensure_ascii=False, indent=2))

        devices_to_plot = result.get("devices", [])
        start_date      = result.get("start_date")
        end_date        = result.get("end_date")

        if not devices_to_plot:
            print("â„¹ï¸  KhÃ´ng tÃ¬m tháº¥y thiáº¿t bá»‹ phÃ¹ há»£p.")
            print("   Gá»£i Ã½: ThÃªm tÃªn vá»‹ trÃ­ cá»¥ thá»ƒ vÃ o cÃ¢u há»i.")
            continue

        if not start_date or not end_date:
            print("âš ï¸  KhÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c khoáº£ng thá»i gian.")
            continue

        # â”€â”€ BÆ¯á»šC 2: Láº¥y dá»¯ liá»‡u tá»« Newsense â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\nâ³ Äang táº£i dá»¯ liá»‡u tá»« Newsense...")
        fetched_data = []

        for device_info in devices_to_plot:
            device_name     = device_info.get("Device")
            data_key        = device_info.get("TÃªn biáº¿n")
            full_name_label = device_info.get("TÃªn thiáº¿t bá»‹", device_name)

            if not device_name or not data_key:
                continue

            device_id = device_name_to_id_map.get(device_name)
            if not device_id:
                matches = difflib.get_close_matches(device_name, device_name_to_id_map.keys(), n=1, cutoff=0.8)
                if matches:
                    print(f"   - Fuzzy match: '{device_name}' â†’ '{matches[0]}'")
                    device_id = device_name_to_id_map[matches[0]]
                else:
                    print(f"   - âš ï¸ KhÃ´ng tÃ¬m tháº¥y: '{device_name}'")
                    continue

            print(f"   - Äang láº¥y: {full_name_label} ({data_key})")

            # Báº¯t lá»—i riÃªng khi táº£i API Ä‘á»ƒ trÃ¡nh sáº­p má»™t thiáº¿t bá»‹ lÃ m há»ng cáº£ quÃ¡ trÃ¬nh
            try:
                df = client.get_timeseries(device_id, data_key, start_date, end_date)
                if not df.empty:
                    fetched_data.append({
                        "label": f"{full_name_label} ({data_key})",
                        "data": df
                    })
                else:
                    print(f"   - â„¹ï¸  KhÃ´ng cÃ³ dá»¯ liá»‡u cho {full_name_label}")
            except Exception as e:
                print(f"   - âŒ Lá»—i khi táº£i {device_name}: {e}")

        if not fetched_data:
            print("ğŸš« KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹ biá»ƒu Ä‘á»“/phÃ¢n tÃ­ch.")
            continue

        # â”€â”€ BÆ¯á»šC 3: Váº½ biá»ƒu Ä‘á»“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("\nğŸ“ˆ Äang táº¡o biá»ƒu Ä‘á»“...")
        num_plots = len(fetched_data)
        fig, axes = plt.subplots(num_plots, 1, figsize=(15, 5 * num_plots), squeeze=False)
        fig.suptitle(f"{query}", fontsize=16, y=1.01)

        for i, item in enumerate(fetched_data):
            df, label = item["data"], item["label"]
            ax = axes[i][0]
            ax.plot(df["ts"], df["value"], label=label, marker=".", linestyle="-", linewidth=1)
            ax.set_title(label, fontsize=12)
            ax.set_xlabel("Thá»i gian")
            ax.set_ylabel("GiÃ¡ trá»‹")
            ax.legend(loc="best")
            ax.grid(True, linestyle="--", linewidth=0.5)

        plt.tight_layout()
        plt.show()

        # FIX QUAN TRá»ŒNG: XÃ³a biá»ƒu Ä‘á»“ khá»i bá»™ nhá»› Colab Ä‘á»ƒ trÃ¡nh treo cho láº§n nháº­p sau
        plt.close('all')

        # â”€â”€ BÆ¯á»šC 4: PhÃ¢n tÃ­ch offline (khÃ´ng cáº§n Gemini) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        analyze_data_offline(fetched_data, query)

        print("\n" + "âœ¨" * 25)
        print("âœ… ÄÃ£ xá»­ lÃ½ xong! Má»i báº¡n cuá»™n xuá»‘ng vÃ  nháº­p cÃ¢u há»i tiáº¿p theo.")
        print("âœ¨" * 25)

    except Exception as e:
        # Náº¿u cÃ³ lá»—i ngáº§m xáº£y ra á»Ÿ báº¥t ká»³ Ä‘Ã¢u, in ra lá»—i vÃ  tiáº¿p tá»¥c vÃ²ng láº·p
        print(f"\nâŒ Lá»–I Há»† THá»NG: {e}")
        import traceback
        traceback.print_exc()
        print("ğŸ”„ Chatbot Ä‘Ã£ tá»± Ä‘á»™ng phá»¥c há»“i. Báº¡n cÃ³ thá»ƒ thá»­ cÃ¢u há»i khÃ¡c.")

